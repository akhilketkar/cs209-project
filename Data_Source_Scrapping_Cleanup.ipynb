{
 "metadata": {
  "name": "",
  "signature": "sha256:8ad53b5daeb4fe8d53a5ad9bf913b90378e26126007eb3dbce80e1fd925fd92d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data Access:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data which was scrapped and pulled from the internet to support our analysis may be accessed on our project's iSite:\n",
      "\n",
      "    https://sites.google.com/a/g.harvard.edu/film_score/data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import lxml.html as lh\n",
      "from datetime import datetime as dt\n",
      "import json\n",
      "import urllib2\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data: Source, scraping method, cleanup"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function below scrapes all the requested movie budgets from \"the-numbers.com,\" and returns the requested data into an external .csv file named: movieBudgets.csv. We employed scraping techniques taught in class to manually scrape this data from the HTML of the website.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getNumbersData():\n",
      "    url = \"http://www.the-numbers.com/movie/budgets/all\"\n",
      "    doc = lh.parse(url)\n",
      "    trs = doc.iter(\"tr\")\n",
      "\n",
      "    l = []\n",
      "    i = 0\n",
      "    for tr in trs:\n",
      "        cont = tr.text_content()\n",
      "        lst = cont.splitlines()\n",
      "        if len(lst) < 5: continue\n",
      "        l.append(lst)\n",
      "        i += 1\n",
      "\n",
      "    data = pd.DataFrame(l)\n",
      "    data.columns = [\"Rank\",\"ReleaseDate\",\"Name\",\"Budget\",\"Domestic\",\"Worldwide\",\"Del\"]\n",
      "    newCols = list(data.columns)\n",
      "    newCols.remove(\"Del\")\n",
      "    data = data[newCols]\n",
      "\n",
      "    data[\"ReleaseDate\"] = data[\"ReleaseDate\"].apply(lambda x: dt.strptime(x,\"%m/%d/%Y\"))\n",
      "    data[\"Budget\"] = data[\"Budget\"].apply(lambda x: x.replace(\"$\",\"\").replace(\",\",\"\"))\n",
      "    data[\"Domestic\"] = data[\"Domestic\"].apply(lambda x: x.replace(\"$\",\"\").replace(\",\",\"\"))\n",
      "    data[\"Worldwide\"] = data[\"Worldwide\"].apply(lambda x: x.replace(\"$\",\"\").replace(\",\",\"\"))\n",
      "\n",
      "    data.Budget = data.Budget.convert_objects(convert_numeric=True)\n",
      "    data.Domestic = data.Domestic.convert_objects(convert_numeric=True)\n",
      "    data.Worldwide = data.Worldwide.convert_objects(convert_numeric=True)\n",
      "\n",
      "    data[\"ReleaseDate\"] = data[\"ReleaseDate\"].apply(lambda x: x.date())\n",
      "    data[\"Year\"] = data[\"ReleaseDate\"].apply(lambda x: x.year)\n",
      "    return data\n",
      "\n",
      "# Create csv file with numbers data\n",
      "data = getNumbersData()\n",
      "data.to_csv(\"movieBudgets.csv\",encoding=\"utf8\",header=True,index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next function below pulls movie reviews using the \"rottentomatoes.com\" API. This data are then placed into a DataFrame and exported to a .csv for analysis, named: movieRTAndBudgetDataAndReviews.csv. Rotten Tomatoes has a request limit of 10,000 per day and 10 calls per second. We had to implement time delays on our request in order to get all of the movie data that we required. This data is formatted for the sentiment analysis portion of the project. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "apiKey = \"u8j7q6zesvbf2mb44abmhfdp\"\n",
      "apiSuffix = \"?apikey=\" + apiKey\n",
      "pageLimitSuffix = \"&page_limit=\"\n",
      "querySuffix =\"&q=\"\n",
      "\n",
      "def getRTReviewDataForMovie(row):\n",
      "    max_results = 50\n",
      "    symbolsToReplace = [\"&\",\":\"]\n",
      "    outDict = {\"Name\":[],\"Rank\":[],\"Critic\":[],\"Date\":[],\"Freshness\":[],\\\n",
      "                 \"Publication\":[],\"Quote\":[],\"Original_Score\":[]}\n",
      "\n",
      "    if len(str(row.RevLink)) < len(\"http://api.rottentomatoes.com/api/public/v1.0/movies/771041731/\"):\n",
      "        print \"No review link found for\", row.Name\n",
      "        return pd.DataFrame(outDict)\n",
      "\n",
      "    queryUrl = str(row.RevLink)\n",
      "    strNameToUse = row.Name.replace(\" \",\"+\")\n",
      "    for s in symbolsToReplace:\n",
      "        strNameToUse = strNameToUse.replace(s,\"\")\n",
      "    finalUrl = queryUrl+apiSuffix+pageLimitSuffix+str(50)\n",
      "\n",
      "    time.sleep(1.)\n",
      "    try:\n",
      "        response = urllib2.urlopen(finalUrl)\n",
      "    except urllib2.HTTPError, e:\n",
      "        print e.fp.read()\n",
      "\n",
      "    jasonText = json.loads(response.read())\n",
      "    numResults = jasonText[\"total\"]\n",
      "    print \"Found\", numResults, \" reviews for\",row.Name\n",
      "\n",
      "    outDict = {\"Name\":[],\"Rank\":[],\"Critic\":[],\"Date\":[],\"Freshness\":[],\\\n",
      "                 \"Publication\":[],\"Quote\":[],\"Original_Score\":[]}\n",
      "\n",
      "    for i in range(min(numResults,max_results)):\n",
      "        review = jasonText[\"reviews\"][i]\n",
      "\n",
      "        for key in outDict.keys():\n",
      "            if key.lower() in review.keys(): outDict[key].append(review[key.lower()])\n",
      "            elif key == \"Name\": outDict[\"Name\"].append(row.Name)\n",
      "            elif key == \"Rank\": outDict[\"Rank\"].append(row.Rank)\n",
      "            else: outDict[key].append(\"N/A\")\n",
      "\n",
      "    # for key,value in outDict.items():\n",
      "    #     print key,len(value)\n",
      "    return pd.DataFrame(outDict)\n",
      "\n",
      "# Load list of movies and get RT data for them\n",
      "\n",
      "min_year = 2009\n",
      "month = 13\n",
      "data = pd.read_csv(\"movieRTAndBudgetData.csv\")\n",
      "data[\"ReleaseDate\"] = data[\"ReleaseDate\"].apply(lambda x: dt.strptime(x,\"%Y-%m-%d\").date())\n",
      "\n",
      "# subset data and query Rotten Tomatoes\n",
      "data2 = data[(data[\"Year\"] > min_year) & (data[\"Month\"] < month)]\n",
      "\n",
      "data3 = pd.DataFrame()\n",
      "for index,row in data2.iterrows():\n",
      "    data3 = pd.concat((data3,getRTReviewDataForMovie(row)),axis=0)\n",
      "\n",
      "print data3.head()\n",
      "data3.to_csv(\"RTReviews.csv\",encoding=\"utf-8\",index=False)\n",
      "\n",
      "# get dataset for pat\n",
      "revDict = {\"Name\":[],\"Reviews_JSON\":[]}\n",
      "groupedData3 = data3.groupby(\"Name\")\n",
      "\n",
      "for name,group in groupedData3:\n",
      "    revList =[r for r in group[\"Quote\"]]\n",
      "\n",
      "    revDict[\"Name\"].append(name)\n",
      "    revDict[\"Reviews_JSON\"].append(json.dumps(revList))\n",
      "\n",
      "data5 = pd.DataFrame(revDict)\n",
      "data5.to_csv(\"movieReviewsPat.csv\",encoding=\"utf-8\",index=False)\n",
      "\n",
      "# merge with numbers data and save\n",
      "data4 = pd.merge(data3,data)\n",
      "data4.to_csv(\"movieRTAndBudgetDataAndReviews.csv\",encoding=\"utf-8\",index=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next function below pulls movie reviews, actors, \"freshness scores\", etc. using the \"rottentomatoes.com\" API. It also combines that with the budget data from above to create a master spreadsheet. This information is then exported to a .csv file, named: movieRTAndBudgetData.csv"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "apiKey = \"u8j7q6zesvbf2mb44abmhfdp\"\n",
      "apiSuffix = \"?apikey=\" + apiKey\n",
      "pageLimitSuffix = \"&page_limit=\"\n",
      "querySuffix =\"&q=\"\n",
      "\n",
      "def getRTDataForMovie(row):\n",
      "    max_results = 50\n",
      "    symbolsToReplace = [\"&\",\":\"]\n",
      "    queryUrl = \"http://api.rottentomatoes.com/api/public/v1.0/movies.json\"\n",
      "\n",
      "    strNameToUse = row.Name.replace(\" \",\"+\")\n",
      "    for s in symbolsToReplace:\n",
      "        strNameToUse = strNameToUse.replace(s,\"\")\n",
      "\n",
      "    finalUrl = queryUrl+apiSuffix+querySuffix+strNameToUse+pageLimitSuffix+str(50)\n",
      "\n",
      "    time.sleep(1.)\n",
      "    try:\n",
      "        response = urllib2.urlopen(finalUrl)\n",
      "    except urllib2.HTTPError, e:\n",
      "        print e.fp.read()\n",
      "\n",
      "    jasonText = json.loads(response.read())\n",
      "    numResults = jasonText[\"total\"]\n",
      "    outSeries = {\"Name\":row.Name,\"Rank\":row.Rank,\"RTID\":None,\"RTData\":None,\"Ratings\":None,\\\n",
      "                 \"AudScore\":None,\"CriticsScore\":None,\"Cast\":None,\"RevLink\":None}\n",
      "    foundFlag = 0\n",
      "\n",
      "    for i in range(min(numResults,max_results)):\n",
      "        movie = jasonText[\"movies\"][i]\n",
      "        if movie[\"year\"] == row.Year:\n",
      "            print \"Found\", movie[\"title\"],\"as\",row.Name\n",
      "            foundFlag = 1\n",
      "            outSeries[\"RTID\"] = movie[\"id\"]\n",
      "            outSeries[\"RTData\"] = json.dumps(movie)\n",
      "            outSeries[\"Ratings\"] = json.dumps(movie[\"ratings\"])\n",
      "            outSeries[\"AudScore\"] = movie[\"ratings\"][\"audience_score\"]\n",
      "            outSeries[\"CriticsScore\"] = movie[\"ratings\"][\"critics_score\"]\n",
      "            outSeries[\"Cast\"] = json.dumps(movie[\"abridged_cast\"])\n",
      "            outSeries[\"RevLink\"] = movie[\"links\"][\"reviews\"]\n",
      "            break\n",
      "\n",
      "    if foundFlag == 0:\n",
      "        print \"No match found for \",row.Name\n",
      "\n",
      "    return pd.Series(outSeries)\n",
      "\n",
      "# Load list of movies and get RT data for them\n",
      "min_year = 2009\n",
      "month = 13\n",
      "data = pd.read_csv(\"movieBudgets.csv\")\n",
      "data[\"ReleaseDate\"] = data[\"ReleaseDate\"].apply(lambda x: dt.strptime(x,\"%Y-%m-%d\").date())\n",
      "data[\"Year\"] = data[\"ReleaseDate\"].apply(lambda x: x.year)\n",
      "data[\"Month\"] = data[\"ReleaseDate\"].apply(lambda x: x.month)\n",
      "\n",
      "# subset data and query Rotten Tomatoes\n",
      "data2 = data[(data[\"Year\"] > min_year) & (data[\"Month\"] < month)]\n",
      "data3 = data2.apply(getRTDataForMovie,1)\n",
      "\n",
      "# merge with numbers data and save\n",
      "data4 = pd.merge(data3,data)\n",
      "data4.to_csv(\"movieRTAndBudgetData.csv\",encoding=\"utf-8\",index=False)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}